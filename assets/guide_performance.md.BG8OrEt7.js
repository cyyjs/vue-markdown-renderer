import{_ as r,c as o,o as t,ag as a}from"./chunks/framework.C0wiDQbp.js";const u=JSON.parse('{"title":"Performance Features & Tips","description":"","frontmatter":{},"headers":[],"relativePath":"guide/performance.md","filePath":"guide/performance.md"}'),n={name:"guide/performance.md"};function i(s,e,d,c,l,p){return t(),o("div",null,[...e[0]||(e[0]=[a('<h1 id="performance-features-tips" tabindex="-1">Performance Features &amp; Tips <a class="header-anchor" href="#performance-features-tips" aria-label="Permalink to &quot;Performance Features &amp; Tips&quot;">​</a></h1><p>The renderer is optimized for streaming and large docs. Key features:</p><ul><li>Incremental parsing for code blocks</li><li>Efficient DOM updates and memory optimizations</li><li>Monaco streaming updates</li><li>Progressive Mermaid rendering</li></ul><p>Performance tips:</p><ul><li>Stream long documents in chunks</li><li>Use <code>MarkdownCodeBlockNode</code> or <code>renderCodeBlocksAsPre</code> for non-editable code</li><li>Scope custom components to enable GC</li><li>Use <code>setDefaultMathOptions</code> at bootstrap</li></ul><h2 id="keeping-a-steady-typewriter-style-stream" tabindex="-1">Keeping a Steady, Typewriter-Style Stream <a class="header-anchor" href="#keeping-a-steady-typewriter-style-stream" aria-label="Permalink to &quot;Keeping a Steady, Typewriter-Style Stream&quot;">​</a></h2><p>Some AI or LLM sources send content in large bursts, which can feel like the preview is freezing and then dumping a whole block. To keep the UI feeling like a smooth, continuous typewriter:</p><ul><li><strong>Keep <code>typewriter</code> enabled</strong> on <code>NodeRenderer</code> (default) so non-code nodes animate in character-by-character instead of appearing instantly.</li><li><strong>Tune the batching props</strong>: drop <code>initialRenderBatchSize</code>/<code>renderBatchSize</code> (for example <code>12</code>/<code>24</code>), and add a small <code>renderBatchDelay</code> (20–30 ms). Even if the model sends a huge chunk, the renderer then inserts tiny slices each frame, producing a stable flow.</li><li><strong>Throttle upstream updates</strong> if possible: instead of replacing <code>content</code> on every incoming hunk, debounce (50–100 ms) or split into smaller paragraphs so each render cycle operates on a “bite-sized” diff.</li><li><strong>Defer heavy nodes</strong> by keeping <code>deferNodesUntilVisible</code>/<code>viewportPriority</code> turned on; expensive blocks (Mermaid/Monaco) will wait until they are near the viewport so the stream of text is never blocked.</li><li><strong>Fall back for code blocks</strong> when a burst happens: disable <code>codeBlockStream</code> or temporarily use <code>renderCodeBlocksAsPre</code> during streaming so that syntax-highlighting work does not stall text updates.</li></ul><p>These knobs keep DOM work under a predictable budget, so users perceive a calm, steady flow of characters even when the backend sends data in erratic bursts.</p>',9)])])}const h=r(n,[["render",i]]);export{u as __pageData,h as default};
